{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from PIL import Image\n",
    "\n",
    "MUSHROOMS_PATH = 'mushrooms_dataset'\n",
    "\n",
    "# Directory for the images and its subdirectories\n",
    "images_dir = os.path.join(MUSHROOMS_PATH, 'images')\n",
    "subdirs = [os.path.join(images_dir, subdir) for subdir in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, subdir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have some ideas for dividing the dataset into training and testing sets. We can use the train_test_split function from scikit-learn to divide the dataset into training and testing sets.\n",
    "#But for that we will have to put the every image into array and then into a dataframe\n",
    "#Then we will have to use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe\n",
    "\n",
    "#Second idea is to manually create the test set by taking 20% of the images from each class and putting them into a separate directory.\n",
    "#We will then use ImageDataGenerator and flow_from_directory to load the images from the directory.\n",
    "\n",
    "#In both ideas we need to take in consider stratification, so that the distribution of classes in the training and testing sets is similar.\n",
    "#For example, if in one class there are 10 images and in another one there are 8 images, we want both  of them to have the same percentage of images in the training and testing sets.\n",
    "\n",
    "#Third idea is to use the splitfolders library to divide the dataset into training and testing sets.\n",
    "#But again we have to stratify the dataset which is not supported by that library.\n",
    "\n",
    "#So the first idea might require a lot of memory usage, the second idea needs us to well do this manually which is not very efficient.\n",
    "#And the third idea is not supporting stratification.\n",
    "\n",
    "#So for now we will use the first idea and divide the dataset into training and testing sets using the train_test_split function from scikit-learn which has the stratify parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the process with the first idea is as follows:\n",
    "#1. Load the images and its corresponding labels into a dataframe.\n",
    "#2. Divide the dataset into training and testing sets using the train_test_split function from scikit-learn with stratification.\n",
    "#3. Use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for subdir in subdirs:\n",
    "    label = os.path.basename(subdir) #we specify the label for each image\n",
    "    for filename in os.listdir(subdir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            data.append((os.path.join(subdir, filename), label)) #we need to include whole path of the image for using flow_from_dataframe because it reads the images directly from the file system using the paths provided in the DataFrame.\n",
    "data_df = pd.DataFrame(data, columns=['filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushrooms_dataset\\images\\Abortiporus_biennis\\1...</td>\n",
       "      <td>Abortiporus_biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushrooms_dataset\\images\\Abortiporus_biennis\\1...</td>\n",
       "      <td>Abortiporus_biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushrooms_dataset\\images\\Abortiporus_biennis\\1...</td>\n",
       "      <td>Abortiporus_biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushrooms_dataset\\images\\Abortiporus_biennis\\1...</td>\n",
       "      <td>Abortiporus_biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushrooms_dataset\\images\\Abortiporus_biennis\\1...</td>\n",
       "      <td>Abortiporus_biennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename                label\n",
       "0  mushrooms_dataset\\images\\Abortiporus_biennis\\1...  Abortiporus_biennis\n",
       "1  mushrooms_dataset\\images\\Abortiporus_biennis\\1...  Abortiporus_biennis\n",
       "2  mushrooms_dataset\\images\\Abortiporus_biennis\\1...  Abortiporus_biennis\n",
       "3  mushrooms_dataset\\images\\Abortiporus_biennis\\1...  Abortiporus_biennis\n",
       "4  mushrooms_dataset\\images\\Abortiporus_biennis\\1...  Abortiporus_biennis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108155 validated image filenames belonging to 1249 classes.\n",
      "Found 36051 validated image filenames belonging to 1249 classes.\n",
      "Found 36052 validated image filenames belonging to 1249 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, shear_range=0.2, validation_split=0.25,) #we use 25% from the 80% of the training set as the validation set which will be the same amount as the testing set\n",
    "\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = datagen_test.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---DONE---\n",
    "#It worked, but why do we have only 6903 classes in the test set and 7504 in training and validation sets? \n",
    "# Perhaps there are not enough images in some classes???\n",
    "\n",
    "# It is probably true beacause when we use stratify parameter in train_test_split function, it tries to keep the distribution of classes in the training and testing sets similar.\n",
    "# But if there are not enough images in some classes, it will not be able to keep the distribution of classes similar in the training and testing sets.\n",
    "# So we have few solutions to this\n",
    "# 1. Ensure that each class has a minimum number of instances before splitting the data into training and testing sets - that worked!!!!\n",
    "# 2. Use the stratify sampling only on the classes with sufficient instances, and randomly split the ones with too few instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could have - we could create our own model but since we have massive amount of images its easier to use pre-trained one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first model\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(7504, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_data, validation_data=val_data, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use couple of models to compare each ones results, its good to create a function for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, model_name):\n",
    "\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    model.save(f'models/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 63, 63, 32)           864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 63, 63, 32)           96        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 63, 63, 32)           0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)           9216      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 61, 61, 32)           96        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 61, 61, 32)           0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 61, 61, 64)           18432     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 61, 61, 64)           192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 61, 61, 64)           0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 64)           0         ['activation_2[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 80)           5120      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 30, 30, 80)           240       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 30, 30, 80)           0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 192)          138240    ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 28, 28, 192)          576       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 28, 28, 192)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 192)          0         ['activation_4[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 13, 13, 64)           192       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 13, 13, 64)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 13, 13, 48)           9216      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 13, 13, 96)           55296     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 13, 13, 48)           144       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 13, 13, 96)           288       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 13, 13, 48)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 13, 13, 96)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 13, 13, 192)          0         ['max_pooling2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)           76800     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 13, 13, 96)           82944     ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 13, 13, 32)           6144      ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 13, 13, 64)           192       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 13, 13, 64)           192       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 13, 13, 96)           288       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 13, 13, 32)           96        ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 13, 13, 64)           0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 13, 13, 64)           0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 13, 13, 256)          0         ['activation_5[0][0]',        \n",
      "                                                                     'activation_7[0][0]',        \n",
      "                                                                     'activation_10[0][0]',       \n",
      "                                                                     'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 13, 13, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 13, 13, 64)           192       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 13, 13, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 13, 13, 96)           55296     ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 13, 13, 48)           144       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 13, 13, 96)           288       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 13, 13, 256)          0         ['mixed0[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 13, 13, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 13, 13, 64)           76800     ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 13, 13, 96)           82944     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 13, 13, 64)           16384     ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 13, 13, 64)           192       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 13, 13, 64)           192       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 13, 13, 96)           288       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 13, 13, 64)           192       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 13, 13, 288)          0         ['activation_12[0][0]',       \n",
      "                                                                     'activation_14[0][0]',       \n",
      "                                                                     'activation_17[0][0]',       \n",
      "                                                                     'activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 13, 13, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 13, 13, 64)           192       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 13, 13, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 13, 13, 96)           55296     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 13, 13, 48)           144       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 13, 13, 96)           288       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (Avera  (None, 13, 13, 288)          0         ['mixed1[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 13, 13, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 13, 13, 64)           76800     ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 13, 13, 96)           82944     ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 13, 13, 64)           18432     ['average_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 13, 13, 64)           192       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 13, 13, 64)           192       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 13, 13, 96)           288       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 13, 13, 64)           192       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 13, 13, 288)          0         ['activation_19[0][0]',       \n",
      "                                                                     'activation_21[0][0]',       \n",
      "                                                                     'activation_24[0][0]',       \n",
      "                                                                     'activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 13, 13, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 13, 13, 64)           192       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 13, 13, 96)           55296     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 13, 13, 96)           288       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 6, 6, 384)            995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 6, 6, 96)             82944     ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 6, 6, 384)            1152      ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 6, 6, 96)             288       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 6, 6, 384)            0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 6, 6, 96)             0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 288)            0         ['mixed2[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 6, 6, 768)            0         ['activation_26[0][0]',       \n",
      "                                                                     'activation_29[0][0]',       \n",
      "                                                                     'max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 6, 6, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 6, 6, 128)            384       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 6, 6, 128)            114688    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 6, 6, 128)            384       ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 6, 6, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 6, 6, 128)            114688    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 6, 6, 128)            384       ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 6, 6, 128)            384       ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 6, 6, 128)            114688    ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 6, 6, 128)            114688    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 6, 6, 128)            384       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 6, 6, 128)            384       ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (Avera  (None, 6, 6, 768)            0         ['mixed3[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 6, 6, 192)            172032    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 6, 6, 192)            172032    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 6, 6, 192)            147456    ['average_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 6, 6, 192)            576       ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 6, 6, 192)            576       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 6, 6, 192)            576       ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 6, 6, 192)            576       ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 6, 6, 768)            0         ['activation_30[0][0]',       \n",
      "                                                                     'activation_33[0][0]',       \n",
      "                                                                     'activation_38[0][0]',       \n",
      "                                                                     'activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 6, 6, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 6, 6, 160)            480       ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 6, 6, 160)            480       ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 6, 6, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 6, 6, 160)            480       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 6, 6, 160)            480       ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 6, 6, 160)            480       ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 6, 6, 160)            480       ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (Avera  (None, 6, 6, 768)            0         ['mixed4[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 6, 6, 192)            147456    ['average_pooling2d_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 6, 6, 192)            576       ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 6, 6, 192)            576       ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 6, 6, 192)            576       ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 6, 6, 192)            576       ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 6, 6, 768)            0         ['activation_40[0][0]',       \n",
      "                                                                     'activation_43[0][0]',       \n",
      "                                                                     'activation_48[0][0]',       \n",
      "                                                                     'activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 6, 6, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (None, 6, 6, 160)            480       ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (None, 6, 6, 160)            480       ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 6, 6, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 6, 6, 160)            480       ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (None, 6, 6, 160)            480       ['conv2d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_56[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, 6, 6, 160)            179200    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, 6, 6, 160)            480       ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (None, 6, 6, 160)            480       ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_57[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (Avera  (None, 6, 6, 768)            0         ['mixed5[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, 6, 6, 192)            147456    ['average_pooling2d_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 6, 6, 192)            576       ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, 6, 6, 192)            576       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (None, 6, 6, 192)            576       ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (None, 6, 6, 192)            576       ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 6, 6, 768)            0         ['activation_50[0][0]',       \n",
      "                                                                     'activation_53[0][0]',       \n",
      "                                                                     'activation_58[0][0]',       \n",
      "                                                                     'activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, 6, 6, 192)            576       ['conv2d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, 6, 6, 192)            576       ['conv2d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_65[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (None, 6, 6, 192)            576       ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, 6, 6, 192)            576       ['conv2d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (None, 6, 6, 192)            576       ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, 6, 6, 192)            576       ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_67[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (Avera  (None, 6, 6, 768)            0         ['mixed6[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 6, 6, 192)            147456    ['average_pooling2d_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (None, 6, 6, 192)            576       ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (None, 6, 6, 192)            576       ['conv2d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, 6, 6, 192)            576       ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, 6, 6, 192)            576       ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_69[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 6, 6, 768)            0         ['activation_60[0][0]',       \n",
      "                                                                     'activation_63[0][0]',       \n",
      "                                                                     'activation_68[0][0]',       \n",
      "                                                                     'activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (Ba  (None, 6, 6, 192)            576       ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_72[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_72[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_73 (Ba  (None, 6, 6, 192)            576       ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_73[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 6, 6, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 6, 6, 192)            258048    ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (None, 6, 6, 192)            576       ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_74 (Ba  (None, 6, 6, 192)            576       ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_70[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_74[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 2, 2, 320)            552960    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, 2, 2, 192)            331776    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (None, 2, 2, 320)            960       ['conv2d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_75 (Ba  (None, 2, 2, 192)            576       ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, 2, 2, 320)            0         ['batch_normalization_71[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, 2, 2, 192)            0         ['batch_normalization_75[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 768)            0         ['mixed7[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, 2, 2, 1280)           0         ['activation_71[0][0]',       \n",
      "                                                                     'activation_75[0][0]',       \n",
      "                                                                     'max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (None, 2, 2, 448)            573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (Ba  (None, 2, 2, 448)            1344      ['conv2d_80[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, 2, 2, 448)            0         ['batch_normalization_80[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (None, 2, 2, 384)            491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (None, 2, 2, 384)            1548288   ['activation_80[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_77 (Ba  (None, 2, 2, 384)            1152      ['conv2d_77[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (None, 2, 2, 384)            1152      ['conv2d_81[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_77[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_81[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (Avera  (None, 2, 2, 1280)           0         ['mixed8[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (None, 2, 2, 320)            409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (Ba  (None, 2, 2, 384)            1152      ['conv2d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_79 (Ba  (None, 2, 2, 384)            1152      ['conv2d_79[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (None, 2, 2, 384)            1152      ['conv2d_82[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (None, 2, 2, 384)            1152      ['conv2d_83[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (None, 2, 2, 192)            245760    ['average_pooling2d_7[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_76 (Ba  (None, 2, 2, 320)            960       ['conv2d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_78[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_79[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_82[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_83[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (None, 2, 2, 192)            576       ['conv2d_84[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, 2, 2, 320)            0         ['batch_normalization_76[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, 2, 2, 768)            0         ['activation_78[0][0]',       \n",
      "                                                                     'activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 2, 2, 768)            0         ['activation_82[0][0]',       \n",
      "                                                                     'activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, 2, 2, 192)            0         ['batch_normalization_84[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, 2, 2, 2048)           0         ['activation_76[0][0]',       \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate[0][0]',         \n",
      "                                                                     'activation_84[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 2, 2, 448)            917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 2, 2, 448)            1344      ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, 2, 2, 448)            0         ['batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (None, 2, 2, 384)            786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (None, 2, 2, 384)            1548288   ['activation_89[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, 2, 2, 384)            1152      ['conv2d_86[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, 2, 2, 384)            1152      ['conv2d_90[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_90[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, 2, 2, 384)            442368    ['activation_90[0][0]']       \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (Avera  (None, 2, 2, 2048)           0         ['mixed9[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, 2, 2, 320)            655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 2, 2, 384)            1152      ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 2, 2, 384)            1152      ['conv2d_88[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, 2, 2, 384)            1152      ['conv2d_91[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 2, 2, 384)            1152      ['conv2d_92[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (None, 2, 2, 192)            393216    ['average_pooling2d_8[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (None, 2, 2, 320)            960       ['conv2d_85[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_91 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_92 (Activation)  (None, 2, 2, 384)            0         ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 2, 2, 192)            576       ['conv2d_93[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, 2, 2, 320)            0         ['batch_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, 2, 2, 768)            0         ['activation_87[0][0]',       \n",
      "                                                                     'activation_88[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 2, 2, 768)            0         ['activation_91[0][0]',       \n",
      " )                                                                   'activation_92[0][0]']       \n",
      "                                                                                                  \n",
      " activation_93 (Activation)  (None, 2, 2, 192)            0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, 2, 2, 2048)           0         ['activation_85[0][0]',       \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_1[0][0]',       \n",
      "                                                                     'activation_93[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['mixed10[0][0]']             \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 2048)                 8192      ['global_average_pooling2d[0][\n",
      " tchNormalization)                                                  0]']                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 2048)                 0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 2098176   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 1024)                 4096      ['dense[0][0]']               \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 1024)                 0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1249)                 1280225   ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25193473 (96.11 MB)\n",
      "Trainable params: 3384545 (12.91 MB)\n",
      "Non-trainable params: 21808928 (83.19 MB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1690/1690 [==============================] - 474s 279ms/step - loss: 22.5368 - accuracy: 0.0385 - val_loss: 7.3382 - val_accuracy: 0.0783\n",
      "Epoch 2/10\n",
      "1690/1690 [==============================] - 457s 270ms/step - loss: 6.9421 - accuracy: 0.0791 - val_loss: 6.5703 - val_accuracy: 0.0958\n",
      "Epoch 3/10\n",
      "1690/1690 [==============================] - 459s 272ms/step - loss: 6.5334 - accuracy: 0.0914 - val_loss: 6.3983 - val_accuracy: 0.1032\n",
      "Epoch 4/10\n",
      "1690/1690 [==============================] - 488s 289ms/step - loss: 6.3661 - accuracy: 0.1005 - val_loss: 6.3041 - val_accuracy: 0.1080\n",
      "Epoch 5/10\n",
      "1690/1690 [==============================] - 1073s 635ms/step - loss: 6.2586 - accuracy: 0.1063 - val_loss: 6.2302 - val_accuracy: 0.1142\n",
      "Epoch 6/10\n",
      "1690/1690 [==============================] - 985s 583ms/step - loss: 6.1781 - accuracy: 0.1127 - val_loss: 6.1810 - val_accuracy: 0.1176\n",
      "Epoch 7/10\n",
      "1690/1690 [==============================] - 947s 560ms/step - loss: 6.1091 - accuracy: 0.1152 - val_loss: 6.1278 - val_accuracy: 0.1206\n",
      "Epoch 8/10\n",
      "1690/1690 [==============================] - 973s 576ms/step - loss: 6.0511 - accuracy: 0.1203 - val_loss: 6.1112 - val_accuracy: 0.1226\n",
      "Epoch 9/10\n",
      "1690/1690 [==============================] - 600s 355ms/step - loss: 5.9987 - accuracy: 0.1228 - val_loss: 6.0797 - val_accuracy: 0.1251\n",
      "Epoch 10/10\n",
      "1690/1690 [==============================] - 460s 272ms/step - loss: 5.9585 - accuracy: 0.1266 - val_loss: 6.0523 - val_accuracy: 0.1288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x242419839d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.08))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "predictions = Dense(1249, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_lr=0.00001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n",
      "4 conv2d_1\n",
      "5 batch_normalization_1\n",
      "6 activation_1\n",
      "7 conv2d_2\n",
      "8 batch_normalization_2\n",
      "9 activation_2\n",
      "10 max_pooling2d\n",
      "11 conv2d_3\n",
      "12 batch_normalization_3\n",
      "13 activation_3\n",
      "14 conv2d_4\n",
      "15 batch_normalization_4\n",
      "16 activation_4\n",
      "17 max_pooling2d_1\n",
      "18 conv2d_8\n",
      "19 batch_normalization_8\n",
      "20 activation_8\n",
      "21 conv2d_6\n",
      "22 conv2d_9\n",
      "23 batch_normalization_6\n",
      "24 batch_normalization_9\n",
      "25 activation_6\n",
      "26 activation_9\n",
      "27 average_pooling2d\n",
      "28 conv2d_5\n",
      "29 conv2d_7\n",
      "30 conv2d_10\n",
      "31 conv2d_11\n",
      "32 batch_normalization_5\n",
      "33 batch_normalization_7\n",
      "34 batch_normalization_10\n",
      "35 batch_normalization_11\n",
      "36 activation_5\n",
      "37 activation_7\n",
      "38 activation_10\n",
      "39 activation_11\n",
      "40 mixed0\n",
      "41 conv2d_15\n",
      "42 batch_normalization_15\n",
      "43 activation_15\n",
      "44 conv2d_13\n",
      "45 conv2d_16\n",
      "46 batch_normalization_13\n",
      "47 batch_normalization_16\n",
      "48 activation_13\n",
      "49 activation_16\n",
      "50 average_pooling2d_1\n",
      "51 conv2d_12\n",
      "52 conv2d_14\n",
      "53 conv2d_17\n",
      "54 conv2d_18\n",
      "55 batch_normalization_12\n",
      "56 batch_normalization_14\n",
      "57 batch_normalization_17\n",
      "58 batch_normalization_18\n",
      "59 activation_12\n",
      "60 activation_14\n",
      "61 activation_17\n",
      "62 activation_18\n",
      "63 mixed1\n",
      "64 conv2d_22\n",
      "65 batch_normalization_22\n",
      "66 activation_22\n",
      "67 conv2d_20\n",
      "68 conv2d_23\n",
      "69 batch_normalization_20\n",
      "70 batch_normalization_23\n",
      "71 activation_20\n",
      "72 activation_23\n",
      "73 average_pooling2d_2\n",
      "74 conv2d_19\n",
      "75 conv2d_21\n",
      "76 conv2d_24\n",
      "77 conv2d_25\n",
      "78 batch_normalization_19\n",
      "79 batch_normalization_21\n",
      "80 batch_normalization_24\n",
      "81 batch_normalization_25\n",
      "82 activation_19\n",
      "83 activation_21\n",
      "84 activation_24\n",
      "85 activation_25\n",
      "86 mixed2\n",
      "87 conv2d_27\n",
      "88 batch_normalization_27\n",
      "89 activation_27\n",
      "90 conv2d_28\n",
      "91 batch_normalization_28\n",
      "92 activation_28\n",
      "93 conv2d_26\n",
      "94 conv2d_29\n",
      "95 batch_normalization_26\n",
      "96 batch_normalization_29\n",
      "97 activation_26\n",
      "98 activation_29\n",
      "99 max_pooling2d_2\n",
      "100 mixed3\n",
      "101 conv2d_34\n",
      "102 batch_normalization_34\n",
      "103 activation_34\n",
      "104 conv2d_35\n",
      "105 batch_normalization_35\n",
      "106 activation_35\n",
      "107 conv2d_31\n",
      "108 conv2d_36\n",
      "109 batch_normalization_31\n",
      "110 batch_normalization_36\n",
      "111 activation_31\n",
      "112 activation_36\n",
      "113 conv2d_32\n",
      "114 conv2d_37\n",
      "115 batch_normalization_32\n",
      "116 batch_normalization_37\n",
      "117 activation_32\n",
      "118 activation_37\n",
      "119 average_pooling2d_3\n",
      "120 conv2d_30\n",
      "121 conv2d_33\n",
      "122 conv2d_38\n",
      "123 conv2d_39\n",
      "124 batch_normalization_30\n",
      "125 batch_normalization_33\n",
      "126 batch_normalization_38\n",
      "127 batch_normalization_39\n",
      "128 activation_30\n",
      "129 activation_33\n",
      "130 activation_38\n",
      "131 activation_39\n",
      "132 mixed4\n",
      "133 conv2d_44\n",
      "134 batch_normalization_44\n",
      "135 activation_44\n",
      "136 conv2d_45\n",
      "137 batch_normalization_45\n",
      "138 activation_45\n",
      "139 conv2d_41\n",
      "140 conv2d_46\n",
      "141 batch_normalization_41\n",
      "142 batch_normalization_46\n",
      "143 activation_41\n",
      "144 activation_46\n",
      "145 conv2d_42\n",
      "146 conv2d_47\n",
      "147 batch_normalization_42\n",
      "148 batch_normalization_47\n",
      "149 activation_42\n",
      "150 activation_47\n",
      "151 average_pooling2d_4\n",
      "152 conv2d_40\n",
      "153 conv2d_43\n",
      "154 conv2d_48\n",
      "155 conv2d_49\n",
      "156 batch_normalization_40\n",
      "157 batch_normalization_43\n",
      "158 batch_normalization_48\n",
      "159 batch_normalization_49\n",
      "160 activation_40\n",
      "161 activation_43\n",
      "162 activation_48\n",
      "163 activation_49\n",
      "164 mixed5\n",
      "165 conv2d_54\n",
      "166 batch_normalization_54\n",
      "167 activation_54\n",
      "168 conv2d_55\n",
      "169 batch_normalization_55\n",
      "170 activation_55\n",
      "171 conv2d_51\n",
      "172 conv2d_56\n",
      "173 batch_normalization_51\n",
      "174 batch_normalization_56\n",
      "175 activation_51\n",
      "176 activation_56\n",
      "177 conv2d_52\n",
      "178 conv2d_57\n",
      "179 batch_normalization_52\n",
      "180 batch_normalization_57\n",
      "181 activation_52\n",
      "182 activation_57\n",
      "183 average_pooling2d_5\n",
      "184 conv2d_50\n",
      "185 conv2d_53\n",
      "186 conv2d_58\n",
      "187 conv2d_59\n",
      "188 batch_normalization_50\n",
      "189 batch_normalization_53\n",
      "190 batch_normalization_58\n",
      "191 batch_normalization_59\n",
      "192 activation_50\n",
      "193 activation_53\n",
      "194 activation_58\n",
      "195 activation_59\n",
      "196 mixed6\n",
      "197 conv2d_64\n",
      "198 batch_normalization_64\n",
      "199 activation_64\n",
      "200 conv2d_65\n",
      "201 batch_normalization_65\n",
      "202 activation_65\n",
      "203 conv2d_61\n",
      "204 conv2d_66\n",
      "205 batch_normalization_61\n",
      "206 batch_normalization_66\n",
      "207 activation_61\n",
      "208 activation_66\n",
      "209 conv2d_62\n",
      "210 conv2d_67\n",
      "211 batch_normalization_62\n",
      "212 batch_normalization_67\n",
      "213 activation_62\n",
      "214 activation_67\n",
      "215 average_pooling2d_6\n",
      "216 conv2d_60\n",
      "217 conv2d_63\n",
      "218 conv2d_68\n",
      "219 conv2d_69\n",
      "220 batch_normalization_60\n",
      "221 batch_normalization_63\n",
      "222 batch_normalization_68\n",
      "223 batch_normalization_69\n",
      "224 activation_60\n",
      "225 activation_63\n",
      "226 activation_68\n",
      "227 activation_69\n",
      "228 mixed7\n",
      "229 conv2d_72\n",
      "230 batch_normalization_72\n",
      "231 activation_72\n",
      "232 conv2d_73\n",
      "233 batch_normalization_73\n",
      "234 activation_73\n",
      "235 conv2d_70\n",
      "236 conv2d_74\n",
      "237 batch_normalization_70\n",
      "238 batch_normalization_74\n",
      "239 activation_70\n",
      "240 activation_74\n",
      "241 conv2d_71\n",
      "242 conv2d_75\n",
      "243 batch_normalization_71\n",
      "244 batch_normalization_75\n",
      "245 activation_71\n",
      "246 activation_75\n",
      "247 max_pooling2d_3\n",
      "248 mixed8\n",
      "249 conv2d_80\n",
      "250 batch_normalization_80\n",
      "251 activation_80\n",
      "252 conv2d_77\n",
      "253 conv2d_81\n",
      "254 batch_normalization_77\n",
      "255 batch_normalization_81\n",
      "256 activation_77\n",
      "257 activation_81\n",
      "258 conv2d_78\n",
      "259 conv2d_79\n",
      "260 conv2d_82\n",
      "261 conv2d_83\n",
      "262 average_pooling2d_7\n",
      "263 conv2d_76\n",
      "264 batch_normalization_78\n",
      "265 batch_normalization_79\n",
      "266 batch_normalization_82\n",
      "267 batch_normalization_83\n",
      "268 conv2d_84\n",
      "269 batch_normalization_76\n",
      "270 activation_78\n",
      "271 activation_79\n",
      "272 activation_82\n",
      "273 activation_83\n",
      "274 batch_normalization_84\n",
      "275 activation_76\n",
      "276 mixed9_0\n",
      "277 concatenate\n",
      "278 activation_84\n",
      "279 mixed9\n",
      "280 conv2d_89\n",
      "281 batch_normalization_89\n",
      "282 activation_89\n",
      "283 conv2d_86\n",
      "284 conv2d_90\n",
      "285 batch_normalization_86\n",
      "286 batch_normalization_90\n",
      "287 activation_86\n",
      "288 activation_90\n",
      "289 conv2d_87\n",
      "290 conv2d_88\n",
      "291 conv2d_91\n",
      "292 conv2d_92\n",
      "293 average_pooling2d_8\n",
      "294 conv2d_85\n",
      "295 batch_normalization_87\n",
      "296 batch_normalization_88\n",
      "297 batch_normalization_91\n",
      "298 batch_normalization_92\n",
      "299 conv2d_93\n",
      "300 batch_normalization_85\n",
      "301 activation_87\n",
      "302 activation_88\n",
      "303 activation_91\n",
      "304 activation_92\n",
      "305 batch_normalization_93\n",
      "306 activation_85\n",
      "307 mixed9_1\n",
      "308 concatenate_1\n",
      "309 activation_93\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:259]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[259:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1690/1690 [==============================] - 555s 326ms/step - loss: 5.8632 - accuracy: 0.1301 - val_loss: 5.5720 - val_accuracy: 0.1625 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "1690/1690 [==============================] - 549s 325ms/step - loss: 5.2624 - accuracy: 0.1833 - val_loss: 5.3207 - val_accuracy: 0.1848 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "1690/1690 [==============================] - 545s 323ms/step - loss: 4.9457 - accuracy: 0.2180 - val_loss: 5.1811 - val_accuracy: 0.2043 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "1690/1690 [==============================] - 547s 323ms/step - loss: 4.6984 - accuracy: 0.2507 - val_loss: 5.1019 - val_accuracy: 0.2149 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "1690/1690 [==============================] - 544s 322ms/step - loss: 4.4786 - accuracy: 0.2817 - val_loss: 5.0200 - val_accuracy: 0.2293 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "1690/1690 [==============================] - 546s 323ms/step - loss: 4.2871 - accuracy: 0.3096 - val_loss: 4.9988 - val_accuracy: 0.2331 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "1690/1690 [==============================] - 542s 321ms/step - loss: 4.1090 - accuracy: 0.3364 - val_loss: 4.9759 - val_accuracy: 0.2415 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "1690/1690 [==============================] - 535s 317ms/step - loss: 3.9402 - accuracy: 0.3631 - val_loss: 4.9862 - val_accuracy: 0.2487 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "1690/1690 [==============================] - 521s 308ms/step - loss: 3.7885 - accuracy: 0.3888 - val_loss: 5.0115 - val_accuracy: 0.2470 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "1690/1690 [==============================] - 520s 308ms/step - loss: 3.6459 - accuracy: 0.4114 - val_loss: 5.0259 - val_accuracy: 0.2546 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "1690/1690 [==============================] - ETA: 0s - loss: 3.5179 - accuracy: 0.4350\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "1690/1690 [==============================] - 520s 308ms/step - loss: 3.5179 - accuracy: 0.4350 - val_loss: 5.0641 - val_accuracy: 0.2540 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "1690/1690 [==============================] - 519s 307ms/step - loss: 2.9016 - accuracy: 0.5362 - val_loss: 4.6558 - val_accuracy: 0.2816 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "1690/1690 [==============================] - 520s 308ms/step - loss: 2.5200 - accuracy: 0.5768 - val_loss: 4.5058 - val_accuracy: 0.2843 - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "1690/1690 [==============================] - 522s 309ms/step - loss: 2.2852 - accuracy: 0.6000 - val_loss: 4.3955 - val_accuracy: 0.2854 - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "1690/1690 [==============================] - 520s 308ms/step - loss: 2.1305 - accuracy: 0.6146 - val_loss: 4.3259 - val_accuracy: 0.2885 - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "1690/1690 [==============================] - 519s 307ms/step - loss: 2.0160 - accuracy: 0.6262 - val_loss: 4.2770 - val_accuracy: 0.2880 - lr: 1.0000e-05\n",
      "Epoch 17/40\n",
      "1690/1690 [==============================] - 520s 308ms/step - loss: 1.9267 - accuracy: 0.6337 - val_loss: 4.2582 - val_accuracy: 0.2862 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "1690/1690 [==============================] - 521s 308ms/step - loss: 1.8619 - accuracy: 0.6413 - val_loss: 4.2298 - val_accuracy: 0.2877 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "1690/1690 [==============================] - 522s 309ms/step - loss: 1.8038 - accuracy: 0.6486 - val_loss: 4.1930 - val_accuracy: 0.2880 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "1690/1690 [==============================] - 525s 311ms/step - loss: 1.7447 - accuracy: 0.6585 - val_loss: 4.2025 - val_accuracy: 0.2859 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "1690/1690 [==============================] - 525s 311ms/step - loss: 1.7120 - accuracy: 0.6631 - val_loss: 4.2024 - val_accuracy: 0.2862 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "1690/1690 [==============================] - 523s 309ms/step - loss: 1.6723 - accuracy: 0.6681 - val_loss: 4.1932 - val_accuracy: 0.2903 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "1690/1690 [==============================] - 521s 308ms/step - loss: 1.6373 - accuracy: 0.6750 - val_loss: 4.1925 - val_accuracy: 0.2875 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "1690/1690 [==============================] - 521s 309ms/step - loss: 1.6073 - accuracy: 0.6802 - val_loss: 4.2022 - val_accuracy: 0.2889 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "1690/1690 [==============================] - 519s 307ms/step - loss: 1.5883 - accuracy: 0.6817 - val_loss: 4.1933 - val_accuracy: 0.2887 - lr: 1.0000e-05\n",
      "Epoch 26/40\n",
      "1690/1690 [==============================] - 519s 307ms/step - loss: 1.5596 - accuracy: 0.6886 - val_loss: 4.2076 - val_accuracy: 0.2879 - lr: 1.0000e-05\n",
      "Epoch 27/40\n",
      "1690/1690 [==============================] - 522s 309ms/step - loss: 1.5281 - accuracy: 0.6940 - val_loss: 4.2138 - val_accuracy: 0.2889 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "1690/1690 [==============================] - 522s 309ms/step - loss: 1.5132 - accuracy: 0.6972 - val_loss: 4.2175 - val_accuracy: 0.2916 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "1690/1690 [==============================] - 521s 308ms/step - loss: 1.4887 - accuracy: 0.7010 - val_loss: 4.2240 - val_accuracy: 0.2924 - lr: 1.0000e-05\n",
      "Epoch 30/40\n",
      "1690/1690 [==============================] - 530s 314ms/step - loss: 1.4722 - accuracy: 0.7047 - val_loss: 4.2236 - val_accuracy: 0.2870 - lr: 1.0000e-05\n",
      "Epoch 31/40\n",
      "1690/1690 [==============================] - 534s 316ms/step - loss: 1.4499 - accuracy: 0.7097 - val_loss: 4.2211 - val_accuracy: 0.2909 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x242755fdc50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=val_data, epochs=40, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 82s 146ms/step - loss: 4.0655 - accuracy: 0.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(test_data)\n",
    "#Save the model\n",
    "saveModel(model, 'inception_v3_mushroomsv1_3_5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
