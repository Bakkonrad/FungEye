{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "from PIL import Image\n",
    "\n",
    "MUSHROOMS_PATH = 'mushrooms_dataset'\n",
    "\n",
    "# Directory for the images and its subdirectories\n",
    "images_dir = os.path.join(MUSHROOMS_PATH, 'images_FasterRCNN', 'images_correct')\n",
    "subdirs = [os.path.join(images_dir, subdir) for subdir in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, subdir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have some ideas for dividing the dataset into training and testing sets. We can use the train_test_split function from scikit-learn to divide the dataset into training and testing sets.\n",
    "#But for that we will have to put the every image into array and then into a dataframe\n",
    "#Then we will have to use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe\n",
    "\n",
    "#Second idea is to manually create the test set by taking 20% of the images from each class and putting them into a separate directory.\n",
    "#We will then use ImageDataGenerator and flow_from_directory to load the images from the directory.\n",
    "\n",
    "#In both ideas we need to take in consider stratification, so that the distribution of classes in the training and testing sets is similar.\n",
    "#For example, if in one class there are 10 images and in another one there are 8 images, we want both  of them to have the same percentage of images in the training and testing sets.\n",
    "\n",
    "#Third idea is to use the splitfolders library to divide the dataset into training and testing sets.\n",
    "#But again we have to stratify the dataset which is not supported by that library.\n",
    "\n",
    "#So the first idea might require a lot of memory usage, the second idea needs us to well do this manually which is not very efficient.\n",
    "#And the third idea is not supporting stratification.\n",
    "\n",
    "#So for now we will use the first idea and divide the dataset into training and testing sets using the train_test_split function from scikit-learn which has the stratify parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the process with the first idea is as follows:\n",
    "#1. Load the images and its corresponding labels into a dataframe.\n",
    "#2. Divide the dataset into training and testing sets using the train_test_split function from scikit-learn with stratification.\n",
    "#3. Use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subdirs) # 181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for subdir in subdirs:\n",
    "    label = os.path.basename(subdir) # we specify the label for each image\n",
    "    for filename in os.listdir(subdir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            data.append((os.path.join(subdir, filename), label)) # we need to include whole path of the image for using flow_from_dataframe because it reads the images directly from the file system using the paths provided in the DataFrame.\n",
    "data_df = pd.DataFrame(data, columns=['filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use 25% from the 80% of the training set as the validation set which will be the same amount as the testing set\n",
    "datagen = ImageDataGenerator( \n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25\n",
    ") \n",
    "\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = datagen_test.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use couple of models to compare each ones results, its good to create a function for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.saved_model import save\n",
    "def saveModel(model, model_name):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    model.save(f'models/{model_name}.h5') #for saving the model in h5 format\n",
    "    model.export(f'models/{model_name}') #for saving the model in saved_model format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "\n",
    "predictions = Dense(181, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) # if the validation loss does not improve for 10 epochs, the training will stop\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=0.000001) # if the validation loss does not improve for 3 epochs, the learning rate will be reduced by a factor of 0.1\n",
    "csv_logger = CSVLogger('model_training.log') # saving the training log to a file\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, validation_data=val_data, epochs=20, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreezing layers from 289\n",
    "for layer in model.layers[:289]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[289:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, validation_data=val_data, epochs=60, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "saveModel(model, 'inception_v3_mushroomsv1_5_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for running the model with TensorFlow Serving\n",
    "# $ docker pull tensorflow/serving:latest-gpu - for pulling the image of TensorFlow Serving\n",
    "# $ docker run --rm -p 8501:8501 --name tfserving_inception -v \"C:\\Users\\Adam\\Desktop\\FungEye\\FungEye\\FungEyeAi\\models\\inception_v3_mushroomsv1_5_5\\:/models/inception/1\" -e MODEL_NAME=inception tensorflow/serving:latest-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((299, 299))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = image.reshape(1, 299, 299, 3)\n",
    "\n",
    "    # specify the endpoint and make the request\n",
    "    endpoint = 'http://localhost:8501/v1/models/inception:predict'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    batch_json = {'signature_name': 'serving_default', 'instances': image.tolist()} #we need to convert the image to a list because the model expects a list of instances\n",
    "\n",
    "    response = requests.post(endpoint, json=batch_json, headers=headers)\n",
    "    predictions = json.loads(response.text)['predictions']\n",
    "\n",
    "    # lets make the predictions more readable, i have a list of class names in the mushroom_names.txt file and we can combine the class names with the predictions\n",
    "    prediction_list = []\n",
    "    with open('mushrooms_dataset/final_mushroom_list.txt', 'r') as file:\n",
    "        class_names = file.read().splitlines()\n",
    "        for i, prediction in enumerate(predictions[0]):\n",
    "            prediction_list.append((class_names[i], prediction))\n",
    "\n",
    "    # Sort the predictions by probability\n",
    "    prediction_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    return prediction_list[:5]\n",
    "\n",
    "predict_image('mushrooms_dataset/borowik_szlachetny.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tensorflow.lite.TFLiteConverter.from_saved_model(\"models/inception_v3_mushroomsv1_3_9\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('models/inception_v3_mushroomsv1_3_9.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
