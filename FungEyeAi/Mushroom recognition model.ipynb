{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "from PIL import Image\n",
    "\n",
    "MUSHROOMS_PATH = 'mushrooms_dataset'\n",
    "\n",
    "# Directory for the images and its subdirectories\n",
    "images_dir = os.path.join(MUSHROOMS_PATH, 'images_FasterRCNN', 'images_correct')\n",
    "subdirs = [os.path.join(images_dir, subdir) for subdir in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, subdir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have some ideas for dividing the dataset into training and testing sets. We can use the train_test_split function from scikit-learn to divide the dataset into training and testing sets.\n",
    "#But for that we will have to put the every image into array and then into a dataframe\n",
    "#Then we will have to use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe\n",
    "\n",
    "#Second idea is to manually create the test set by taking 20% of the images from each class and putting them into a separate directory.\n",
    "#We will then use ImageDataGenerator and flow_from_directory to load the images from the directory.\n",
    "\n",
    "#In both ideas we need to take in consider stratification, so that the distribution of classes in the training and testing sets is similar.\n",
    "#For example, if in one class there are 10 images and in another one there are 8 images, we want both  of them to have the same percentage of images in the training and testing sets.\n",
    "\n",
    "#Third idea is to use the splitfolders library to divide the dataset into training and testing sets.\n",
    "#But again we have to stratify the dataset which is not supported by that library.\n",
    "\n",
    "#So the first idea might require a lot of memory usage, the second idea needs us to well do this manually which is not very efficient.\n",
    "#And the third idea is not supporting stratification.\n",
    "\n",
    "#So for now we will use the first idea and divide the dataset into training and testing sets using the train_test_split function from scikit-learn which has the stratify parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the process with the first idea is as follows:\n",
    "#1. Load the images and its corresponding labels into a dataframe.\n",
    "#2. Divide the dataset into training and testing sets using the train_test_split function from scikit-learn with stratification.\n",
    "#3. Use ImageDataGenerator and flow_from_dataframe to load the images from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for subdir in subdirs:\n",
    "    label = os.path.basename(subdir) #we specify the label for each image\n",
    "    for filename in os.listdir(subdir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            data.append((os.path.join(subdir, filename), label)) #we need to include whole path of the image for using flow_from_dataframe because it reads the images directly from the file system using the paths provided in the DataFrame.\n",
    "data_df = pd.DataFrame(data, columns=['filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushrooms_dataset\\images_FasterRCNN\\images_cor...</td>\n",
       "      <td>Agaricus_arvensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushrooms_dataset\\images_FasterRCNN\\images_cor...</td>\n",
       "      <td>Agaricus_arvensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushrooms_dataset\\images_FasterRCNN\\images_cor...</td>\n",
       "      <td>Agaricus_arvensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushrooms_dataset\\images_FasterRCNN\\images_cor...</td>\n",
       "      <td>Agaricus_arvensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushrooms_dataset\\images_FasterRCNN\\images_cor...</td>\n",
       "      <td>Agaricus_arvensis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename              label\n",
       "0  mushrooms_dataset\\images_FasterRCNN\\images_cor...  Agaricus_arvensis\n",
       "1  mushrooms_dataset\\images_FasterRCNN\\images_cor...  Agaricus_arvensis\n",
       "2  mushrooms_dataset\\images_FasterRCNN\\images_cor...  Agaricus_arvensis\n",
       "3  mushrooms_dataset\\images_FasterRCNN\\images_cor...  Agaricus_arvensis\n",
       "4  mushrooms_dataset\\images_FasterRCNN\\images_cor...  Agaricus_arvensis"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9348 validated image filenames belonging to 172 classes.\n",
      "Found 3116 validated image filenames belonging to 172 classes.\n",
      "Found 3117 validated image filenames belonging to 172 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator( #we use 25% from the 80% of the training set as the validation set which will be the same amount as the testing set\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25\n",
    ") \n",
    "\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_data = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = datagen_test.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(299, 299),\n",
    "    class_mode='categorical',\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---DONE---\n",
    "#It worked, but why do we have only 6903 classes in the test set and 7504 in training and validation sets? \n",
    "# Perhaps there are not enough images in some classes???\n",
    "\n",
    "# It is probably true beacause when we use stratify parameter in train_test_split function, it tries to keep the distribution of classes in the training and testing sets similar.\n",
    "# But if there are not enough images in some classes, it will not be able to keep the distribution of classes similar in the training and testing sets.\n",
    "# So we have few solutions to this\n",
    "# 1. Ensure that each class has a minimum number of instances before splitting the data into training and testing sets - that worked!!!!\n",
    "# 2. Use the stratify sampling only on the classes with sufficient instances, and randomly split the ones with too few instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could have - we could create our own model but since we have massive amount of images its easier to use pre-trained one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first model\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(7504, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_data, validation_data=val_data, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use couple of models to compare each ones results, its good to create a function for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.saved_model import save\n",
    "def saveModel(model, model_name):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    model.save(f'models/{model_name}.h5') #for saving the model in h5 format\n",
    "    model.export(f'models/{model_name}') #for saving the model in saved_model format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "\n",
    "predictions = Dense(181, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "# optimizer - RMSprop(learning_rate=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=0.000001)\n",
    "csv_logger = CSVLogger('model_training.log')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, validation_data=val_data, epochs=20, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:289]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[289:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, validation_data=val_data, epochs=60, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 202ms/step - accuracy: 0.4873 - loss: 2.8171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8508753776550293, 0.47667887806892395]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "saveModel(model, 'inception_v3_mushroomsv1_5_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tensorflow.keras.models.load_model('models/inception_v3_mushroomsv1_3_5.h5')\n",
    "# model.export('models/inception_v3_mushroomsv1_3_5_SavedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for running the model with TensorFlow Serving\n",
    "# $ docker pull tensorflow/serving:latest-gpu - for pulling the image of TensorFlow Serving\n",
    "# $ docker run --rm -p 8501:8501 --name tfserving_inception -v \"C:\\Users\\Adam\\Desktop\\FungEye\\FungEye\\FungEyeAi\\models\\inception_v3_mushroomsv1_3_5_SavedModel\\1:/models/inception/1\" -e MODEL_NAME=inception tensorflow/serving:latest-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((299, 299))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = image.reshape(1, 299, 299, 3)\n",
    "\n",
    "    # specify the endpoint and make the request\n",
    "    endpoint = 'http://localhost:8501/v1/models/inception:predict'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    batch_json = {'signature_name': 'serving_default', 'instances': image.tolist()} #we need to convert the image to a list because the model expects a list of instances\n",
    "\n",
    "    response = requests.post(endpoint, json=batch_json, headers=headers)\n",
    "    predictions = json.loads(response.text)['predictions']\n",
    "\n",
    "    # lets make the predictions more readable, i have a list of class names in the mushroom_names.txt file and we can combine the class names with the predictions\n",
    "    prediction_list = []\n",
    "    with open('mushroom_names.txt', 'r') as file:\n",
    "        class_names = file.read().splitlines()\n",
    "        for i, prediction in enumerate(predictions[0]):\n",
    "            prediction_list.append((class_names[i], prediction))\n",
    "\n",
    "    # Sort the predictions by probability\n",
    "    prediction_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    return prediction_list[:5]\n",
    "\n",
    "predict_image('mushrooms_dataset/images_FasterRCNN/images_correct/Cryptoporus_volvatus/5555.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tensorflow.lite.TFLiteConverter.from_saved_model(\"models/inception_v3_mushroomsv1_3_9\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('models/inception_v3_mushroomsv1_3_9.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
